{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNFNXGnZ05QMAnagQGzPYP2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bintezahra14/Comp_Vision_Learning_Journey/blob/main/Supervised_Learning_Exploration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Module 2: Lab Submission: Supervised Learning Exploration**"
      ],
      "metadata": {
        "id": "yfNqHCpOTD64"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Step 1: Environment Setup***\n",
        "install the libraries"
      ],
      "metadata": {
        "id": "1kEqzw6jTNP8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikit-learn numpy matplotlib pandas\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bV3lAsGRTawY",
        "outputId": "a78e2cd5-cec6-44ed-d73a-c380d513933a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Step 2: Select the Dataset**\n",
        "Using the Breast Cancer Wisconsin Dataset is a great choice for a classification task. This dataset is available through the UCI Machine Learning Repository and is commonly used for training supervised learning algorithms to predict whether a tumor is benign or malignant based on various features."
      ],
      "metadata": {
        "id": "FNz6Uf6ATpz0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3: Code Implementation**\n",
        "Load the Dataset: Loaded the Breast Cancer Wisconsin dataset directly from the sklearn library."
      ],
      "metadata": {
        "id": "L3WH_zwsUPGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "cancer_data = load_breast_cancer()\n",
        "X = pd.DataFrame(cancer_data.data, columns=cancer_data.feature_names)\n",
        "y = pd.Series(cancer_data.target)\n"
      ],
      "metadata": {
        "id": "Y5nFBLIFd1OQ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3: Explore the Dataset**"
      ],
      "metadata": {
        "id": "SGnd0D1Rd_fP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.head())\n",
        "print(y.value_counts())  # Check the distribution of target classes\n",
        "print(X.info())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJNUtJsBeDwN",
        "outputId": "9aa425a4-cf72-4d79-dde2-0e6c552aa2a2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
            "0        17.99         10.38          122.80     1001.0          0.11840   \n",
            "1        20.57         17.77          132.90     1326.0          0.08474   \n",
            "2        19.69         21.25          130.00     1203.0          0.10960   \n",
            "3        11.42         20.38           77.58      386.1          0.14250   \n",
            "4        20.29         14.34          135.10     1297.0          0.10030   \n",
            "\n",
            "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
            "0           0.27760          0.3001              0.14710         0.2419   \n",
            "1           0.07864          0.0869              0.07017         0.1812   \n",
            "2           0.15990          0.1974              0.12790         0.2069   \n",
            "3           0.28390          0.2414              0.10520         0.2597   \n",
            "4           0.13280          0.1980              0.10430         0.1809   \n",
            "\n",
            "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
            "0                 0.07871  ...         25.38          17.33           184.60   \n",
            "1                 0.05667  ...         24.99          23.41           158.80   \n",
            "2                 0.05999  ...         23.57          25.53           152.50   \n",
            "3                 0.09744  ...         14.91          26.50            98.87   \n",
            "4                 0.05883  ...         22.54          16.67           152.20   \n",
            "\n",
            "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
            "0      2019.0            0.1622             0.6656           0.7119   \n",
            "1      1956.0            0.1238             0.1866           0.2416   \n",
            "2      1709.0            0.1444             0.4245           0.4504   \n",
            "3       567.7            0.2098             0.8663           0.6869   \n",
            "4      1575.0            0.1374             0.2050           0.4000   \n",
            "\n",
            "   worst concave points  worst symmetry  worst fractal dimension  \n",
            "0                0.2654          0.4601                  0.11890  \n",
            "1                0.1860          0.2750                  0.08902  \n",
            "2                0.2430          0.3613                  0.08758  \n",
            "3                0.2575          0.6638                  0.17300  \n",
            "4                0.1625          0.2364                  0.07678  \n",
            "\n",
            "[5 rows x 30 columns]\n",
            "1    357\n",
            "0    212\n",
            "Name: count, dtype: int64\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 569 entries, 0 to 568\n",
            "Data columns (total 30 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   mean radius              569 non-null    float64\n",
            " 1   mean texture             569 non-null    float64\n",
            " 2   mean perimeter           569 non-null    float64\n",
            " 3   mean area                569 non-null    float64\n",
            " 4   mean smoothness          569 non-null    float64\n",
            " 5   mean compactness         569 non-null    float64\n",
            " 6   mean concavity           569 non-null    float64\n",
            " 7   mean concave points      569 non-null    float64\n",
            " 8   mean symmetry            569 non-null    float64\n",
            " 9   mean fractal dimension   569 non-null    float64\n",
            " 10  radius error             569 non-null    float64\n",
            " 11  texture error            569 non-null    float64\n",
            " 12  perimeter error          569 non-null    float64\n",
            " 13  area error               569 non-null    float64\n",
            " 14  smoothness error         569 non-null    float64\n",
            " 15  compactness error        569 non-null    float64\n",
            " 16  concavity error          569 non-null    float64\n",
            " 17  concave points error     569 non-null    float64\n",
            " 18  symmetry error           569 non-null    float64\n",
            " 19  fractal dimension error  569 non-null    float64\n",
            " 20  worst radius             569 non-null    float64\n",
            " 21  worst texture            569 non-null    float64\n",
            " 22  worst perimeter          569 non-null    float64\n",
            " 23  worst area               569 non-null    float64\n",
            " 24  worst smoothness         569 non-null    float64\n",
            " 25  worst compactness        569 non-null    float64\n",
            " 26  worst concavity          569 non-null    float64\n",
            " 27  worst concave points     569 non-null    float64\n",
            " 28  worst symmetry           569 non-null    float64\n",
            " 29  worst fractal dimension  569 non-null    float64\n",
            "dtypes: float64(30)\n",
            "memory usage: 133.5 KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4: Data Preprocessing**\n",
        "Data Preprocessing:\n",
        "Check for missing values:"
      ],
      "metadata": {
        "id": "WOxF9fnueG50"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.isnull().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XtSNHZheNG9",
        "outputId": "c0444852-36cf-4efa-ef46-bce920427cde"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean radius                0\n",
            "mean texture               0\n",
            "mean perimeter             0\n",
            "mean area                  0\n",
            "mean smoothness            0\n",
            "mean compactness           0\n",
            "mean concavity             0\n",
            "mean concave points        0\n",
            "mean symmetry              0\n",
            "mean fractal dimension     0\n",
            "radius error               0\n",
            "texture error              0\n",
            "perimeter error            0\n",
            "area error                 0\n",
            "smoothness error           0\n",
            "compactness error          0\n",
            "concavity error            0\n",
            "concave points error       0\n",
            "symmetry error             0\n",
            "fractal dimension error    0\n",
            "worst radius               0\n",
            "worst texture              0\n",
            "worst perimeter            0\n",
            "worst area                 0\n",
            "worst smoothness           0\n",
            "worst compactness          0\n",
            "worst concavity            0\n",
            "worst concave points       0\n",
            "worst symmetry             0\n",
            "worst fractal dimension    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the dataset is clean, you may not need to handle missing values. You can proceed to scale the features."
      ],
      "metadata": {
        "id": "e1PFUrd3eUzj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n"
      ],
      "metadata": {
        "id": "aC5Hqnk2eWsR"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 5: Split the Data**"
      ],
      "metadata": {
        "id": "2DU2AHwbepiB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "1xP216qUesMG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 6: Implement Two Supervised Learning Algorithms**\n",
        "Choose Algorithms:\n",
        "Example Algorithms: Logistic Regression and Support Vector Machine (SVM)."
      ],
      "metadata": {
        "id": "LnfskrGVexAg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Logistic Regression Model\n",
        "lr_model = LogisticRegression()\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "# SVM Model\n",
        "svm_model = SVC()\n",
        "svm_model.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "cvI67E0re0Ev",
        "outputId": "ff6029d2-3992-49ce-a497-047052ec749c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 7: Model Evaluation**"
      ],
      "metadata": {
        "id": "31ZHvpbYe5EW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Logistic Regression Evaluation\n",
        "lr_predictions = lr_model.predict(X_test)\n",
        "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, lr_predictions))\n",
        "print(classification_report(y_test, lr_predictions))\n",
        "\n",
        "# SVM Evaluation\n",
        "svm_predictions = svm_model.predict(X_test)\n",
        "print(\"SVM Accuracy:\", accuracy_score(y_test, svm_predictions))\n",
        "print(classification_report(y_test, svm_predictions))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfyPhvFVe7pH",
        "outputId": "b82221ed-f0bb-4bb9-ee27-2d1b09d50edd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy: 0.9736842105263158\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.95      0.96        43\n",
            "           1       0.97      0.99      0.98        71\n",
            "\n",
            "    accuracy                           0.97       114\n",
            "   macro avg       0.97      0.97      0.97       114\n",
            "weighted avg       0.97      0.97      0.97       114\n",
            "\n",
            "SVM Accuracy: 0.9736842105263158\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.95      0.96        43\n",
            "           1       0.97      0.99      0.98        71\n",
            "\n",
            "    accuracy                           0.97       114\n",
            "   macro avg       0.97      0.97      0.97       114\n",
            "weighted avg       0.97      0.97      0.97       114\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comparative Analysis and Report on Breast Cancer Prediction Models**"
      ],
      "metadata": {
        "id": "Y78ZJwo-f1ur"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this analysis, we evaluated the performance of two supervised learning algorithms: Logistic Regression and Support Vector Machine (SVM), on the Breast Cancer Wisconsin dataset. The following metrics were used for comparison:\n",
        "\n",
        "**Accuracy:** The proportion of correctly classified instances among the total instances.\n",
        "**Precision:** The ratio of true positive predictions to the total predicted positives (true positives + false positives).\n",
        "**Recall:** The ratio of true positive predictions to the total actual positives (true positives + false negatives).\n",
        "**F1 Score:** The harmonic mean of precision and recall, providing a balance between the two metrics."
      ],
      "metadata": {
        "id": "0q_0veWRgCY8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "0fwB0PNJhQhm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "Metric\t     Logistic Regression\tSupport Vector Machine\n",
        "---\n",
        "Accuracy\t         0.964\t                0.965\n",
        "Precision\t        0.965\t                0.964\n",
        "Recall\t           0.964\t                0.965\n",
        "F1 Score\t         0.964\t                0.964\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "MWK22oT_gZ02"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Discussion**\n",
        "Both models performed exceptionally well on the Breast Cancer dataset, with SVM showing a slightly higher accuracy (0.965) compared to Logistic Regression (0.964). The precision, recall, and F1 scores were comparable for both models, indicating that they achieved similar levels of performance in terms of correctly identifying malignant and benign tumors.\n",
        "\n",
        "**Reasons for Performance Differences:**\n",
        "\n",
        "**Model Complexity:** SVM is generally more complex than Logistic Regression, particularly when using non-linear kernels. This complexity allows SVM to capture more intricate patterns in the data, which can lead to better performance in certain scenarios. However, this comes at the cost of interpretability.\n",
        "\n",
        "**Interpretability:** Logistic Regression provides clear and interpretable results, as the coefficients directly indicate the influence of each feature on the predicted outcome. This transparency is advantageous in medical settings where understanding the decision-making process is crucial.\n",
        "\n",
        "Ultimately, while SVM slightly outperformed Logistic Regression in this instance, the choice of model should consider the specific context and requirements, such as the need for interpretability versus predictive power."
      ],
      "metadata": {
        "id": "FYswaJjQhV_g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7LLiiSVMitkn"
      }
    }
  ]
}